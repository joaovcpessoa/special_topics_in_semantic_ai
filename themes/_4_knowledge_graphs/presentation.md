### Sobre as referÃªncias

- Cognitive Semantics of Artificial Intelligence
- Semantic AI in Knowledge Graphs
- Semantic Web for the Working Ontologist

NÃ£o foram adicionadas por limitaÃ§Ã£o de armazenamento, jÃ¡ que sÃ£o livros extensos sobre o tema.

### INTRO

Eu sou o JoÃ£o e gostaria de enfartizar antes de tudo, o poder das conexÃµes.
Eu conheÃ§o o Rafael, que conhece o Marcelo, que conhece o Diniz, que conhece o Shannon, que conhece o Boole.

Brincadeiras a parte, a noÃ§Ã£o que estamos a cerca de 6 apertos de mÃ£o de qualquer pessoa do mundo vem em grande parte do experimento de Stanley Milgram, de 1967. Um sociÃ³logo que queria medir a distÃ¢ncia entre as pessoas nos EUA, entÃ£o ele escolheu 2 destinatÃ¡rios na regiÃ£o de Boston e pediu para voluntÃ¡rios que moravam pelo paÃ­s fazerem uma carta chegar para essas pessoas passando por intermediÃ¡rios que podiam ou nÃ£o conhecer os destinatÃ¡rios ou alguÃ©m lÃ¡ no meio. AtÃ© entÃ£o nÃ£o se fazia ideia de quantos passos seriam necessÃ¡rios. Das 160 cartas iniciais, 42 chegaram atÃ© o destino final e na mÃ©dia, elas precisaram passar por pouco menos do que 6 intermediÃ¡rios. Essa noÃ§Ã£o foi explorada em uma peÃ§a que depois virou um filme chamado SEIS GRAUS DE SEPARAÃ‡ÃƒO.

Claro que dizer que as cartas que chegaram ao destino explicam a quantos intermediÃ¡rios as pessoas estÃ£o no mundo todo Ã© forÃ§ar um pouco a barra. Isso pode ser medido de outra forma e quem pode explicar isso Ã© o estudo das redes complexas e a teoria dos grafos, que podemos atribuir a criaÃ§Ã£o ao matemÃ¡tico suÃ­Ã§o Leonhard Euler. Para quem quiser saber mais sobre o tema eu deixo de recomendaÃ§Ã£o o Livro Linked, escrito por Laszlo Barabasi, outro cara brilhante que mostra entre os muitos grandes feitos de Euler, a resoluÃ§Ã£o do desafio das pontes do Rio Pregel, em KÃ¶nigsberg, hoje conhecida como Kaliningrado. Em 1735, o Rio Pregel que corta a cidade tinha 7 pontes que cortavam a cidade e ligavam ela a pequenina ilha de Kneiphof e o desafio da Ã©poca era atravessar todas as pontes sem repetir nenhuma. Ele representou cada ponte como traÃ§os e as margens como nÃ³s ou vÃ©rtices e em 1736 mostrou que o desafio era impossÃ­vel. Depois demonstrou que, para existir um caminho que passe por todas as arestas sem repetir nenhuma, no mÃ¡ximo dois nÃ³s podem ter grau Ã­mpar. Como todos os quatro nÃ³s do mapa original tinham grau Ã­mpar, o problema nÃ£o tinha soluÃ§Ã£o.

Certo, mas o que isso tem haver com grafos de conhecimento? Ai que eu lhe digo, tudo, deixa eu te mostrar a conexÃ£o.

Hoje em dia estamos vivendo em uma era de fatura de dados, mesmo sem compreender de fato o significado de alguns. E se uma mÃ¡quina fosse capaz de fazer conexÃµes que passam despercebidas por nÃ³s humanos? Vamos falar sobre uma tecnologia capaz de ensinar computadores nÃ£o somente a ler dados, mas entender de verdade seu significado. Para um computador, 'NASA' e 'missÃ£o espacial' sÃ£o apenas sequencias de bits, nÃ£o ideias que se conectam, falta o entendimento do contexto que para nÃ³s Ã© quase instintivo. Ã‰ como se colocassemos uma crianÃ§a para ler uma lista telefÃ´nica (antigo ein, quem lembra o que Ã© isso?) e ela dirÃ¡: 'Certo, tem um montÃ£o de palavras e nÃºmeros, mas onde estÃ¡ a histÃ³ria?'. Justamente essa barreira que o conceito de IA SemÃ¢ntica busca derrubar. Uma das soluÃ§Ãµes para isso Ã© uma ideia que particularmente considero ao mesmo tempo elegante e genial. Utilizar grafos de conhecimento.

### DEFINITION

Vamos comeÃ§ar pelo bÃ¡sico. Imagine que vocÃª estÃ¡ assistindo a um jogo de futebol. VocÃª pode criar um grafo de conhecimento bem simples com base no que vocÃª vÃª. Basta representar cada jogador em campo como um nÃ³ e use uma linha ou aresta para conectar os nÃ³s com base nas aÃ§Ãµes que eles realizam, como passar a bola. Essa teia de jogadores e suas aÃ§Ãµes Ã© um exemplo de Grafo de Conhecimento.

De forma mais geral, os nÃ³s representam entidades, como pessoas, lugares ou coisas, e as arestas representam os relacionamentos entre elas. Ã‰ uma forma de organizar a informaÃ§Ã£o que destaca conexÃµes e interaÃ§Ãµes. Cada nÃ³ pode armazenar dados ricos; no exemplo do futebol, isso poderia ser as estatÃ­sticas de um jogador, sua posiÃ§Ã£o ou atÃ© mesmo seu desempenho histÃ³rico. As arestas tambÃ©m podem armazenar dados, como pesos que representam o nÃºmero de passes entre os jogadores. E, uma vez que o grafo de conhecimento estÃ¡ completo, vocÃª pode usÃ¡-lo para fazer previsÃµes sobre os resultados dos jogos, descobrir os melhores jogadores para recrutar para um time, e mais.

Como isso difere de um banco de dados ou planilha tradicional? Em ambos os casos, a informaÃ§Ã£o Ã© armazenada em tabelas com linhas e colunas. Isso Ã© Ã³timo para dados estruturados, mas rapidamente se torna impraticÃ¡vel ao lidar com relacionamentos complexos. Um Grafo de Conhecimento, por outro lado, Ã© como um mapa de dados, onde vocÃª pode ver facilmente como tudo estÃ¡ conectado e pode realizar operaÃ§Ãµes matemÃ¡ticas em diferentes partes do mapa.

Vamos pensar nele como uma espÃ©cie de cÃ©rebro digital. Em vez de armazenarmos palavras isoladas, ele mapeia as relaÃ§Ãµes entre as coisas, portanto ao guardarmos a palavra 'NASA', ele conecta a ideia de que essa palavra significa 'uma organizaÃ§Ã£o que realiza missÃµes espaciais'. Tecendo uma teia de  compreensÃ£o.

Isso torna possÃ­vel descobrir insights e padrÃµes que nÃ£o sÃ£o imediatamente Ã³bvios em um banco de dados ou planilha. Por exemplo, vocÃª pode rastrear a frequÃªncia com que os jogadores interagem ou como vÃ¡rias proteÃ­nas interagem em uma cÃ©lula biolÃ³gica. Os grafos de conhecimento tambÃ©m permitem que vocÃª adicione facilmente novos tipos de relacionamentos entre os dados e que extrapole a partir dos dados, o que pode ser usado para inferir e validar a aplicabilidade do nosso conhecimento atual Ã s nossas previsÃµes.

A construÃ§Ã£o e anÃ¡lise de grafos de conhecimento envolve ferramentas matemÃ¡ticas e de programaÃ§Ã£o avanÃ§adas e pode incorporar aprendizado de mÃ¡quina (machine learning). Bibliotecas de software podem ajudar a gerenciar as estruturas do grafo e realizar operaÃ§Ãµes como anÃ¡lise do caminho mais curto (shortest path analysis), medidas de centralidade e detecÃ§Ã£o de comunidade. Enquanto algoritmos podem calcular similaridades e prever novas conexÃµes ou relaÃ§Ãµes causais.

Como eu falei antes, esse conhecimento pode ser usado em vÃ¡rias Ã¡reas.

Em mÃ­dias sociais, um Grafo de Conhecimento pode mapear suas conexÃµes e interesses. Se seu amigo ama um restaurante especÃ­fico, a plataforma pode recomendar o mesmo restaurante a vocÃª, com base na forÃ§a da conexÃ£o com seu amigo e nos outros dados relacionados Ã s suas preferÃªncias alimentares e lugares que vocÃª gosta de visitar. Sim, isso Ã© invasivo e todos nÃ³s assinamos que concordamos com os termos de serviÃ§os.

Nem sempre Ã© algo tÃ£o amedrontador, pode ser usado por exemplo na descoberta de novas drogas, ajudando os pesquisadores a gerenciar e analisar vastas quantidades de dados biolÃ³gicos. Eles podem prever como uma nova droga pode interagir com proteÃ­nas no corpo, identificando alvos de doenÃ§as para drogas e potenciais efeitos colaterais, economizando tempo e recursos significativos no processo de pesquisa.

Essa proposta de grafos veio como uma forma diferente de armazenar, gerenciar e analisar nossos dados, tornando possÃ­vel manipular eficientemente conjuntos de dados complexos, revelar conexÃµes intrincadas e facilitar decisÃµes poderosas baseadas em dados, mesmo quando temos informaÃ§Ãµes limitadas sobre um assunto. Seja ajudando vocÃª a encontrar seu prÃ³ximo restaurante favorito ou descobrindo medicamentos que salvam vidas, os grafos de conhecimento sÃ£o a teia de nossos insights compartilhados e validados, e estÃ£o moldando o futuro da tecnologia e da ciÃªncia.

Tudo parece muito lindo atÃ© aqui, mas vamos entender o tamanho do problema que essa tecnologia se propÃµe a resolver. Vamos entrar no labirinto do fauno, quer dizer, de dados.

### PROBLEM

O grande problema Ã© que nossos dados se parecem bastante com nossos bilionÃ¡rios. Vivem em ilhas completamente isolados. Deixe-me formular corretamente: O problema Ã© a fragmentaÃ§Ã£o epistemolÃ³gica.

Parece atÃ© um golpe de cavaleiros do ZodiÃ¡co, mas nÃ£o Ã©. FragmentaÃ§Ã£o epistemolÃ³gica Ã© o processo em que o conhecimento deixa de ser percebido como um todo integrado e passa a ficar dividido em partes isoladas, que nÃ£o se comunicam bem entre si. Em outras palavras: Ã© quando saberes que deveriam dialogar acabam se tornando â€œilhasâ€.

Exemplo simples: Um problema social como a violÃªncia pode ter causas econÃ´micas, psicolÃ³gicas, polÃ­ticas e culturais, mas cada Ã¡rea estuda sÃ³ a sua parte, sem integrar nada. Assim um grupo diz que a culpa Ã© da desigualdade econÃ´mica, outro diz que a culpa foi da ausÃªncia ou mÃ¡ criaÃ§Ã£o dos pais, outro diz isso Ã© resultado dos ideais de um grupo polÃ­tico e jÃ¡ outros que considero mais inteligentes que atribuem isso a fatores culturais histÃ³ricos, afinal o que se pode esperar de um paÃ­s forjado pela escravidÃ£o que serviu de prisÃ£o para criminosos e todo tipo excluÃ­dos das sociedades europeias? Enfim, Ã© algo que possui vÃ¡rias condiÃ§Ãµes de anÃ¡lise.

O desafio aqui Ã©:

Pense em cada base de dados como uma ilha: artigo cientÃ­fico, relatÃ³rio policial, exame laboratorial, notÃ­cia jornalÃ­stica, conversa em rede social.

As relaÃ§Ãµes existem, mas:
- estÃ£o distribuÃ­das
- nÃ£o sÃ£o estruturadas
- nÃ£o tÃªm semÃ¢ntica explÃ­cita

Sem integraÃ§Ã£o semÃ¢ntica, nÃ£o hÃ¡:
- inferÃªncia
- consolidaÃ§Ã£o
- descoberta de padrÃµes

Essas conexÃµes ausentes podem significar um risco real:
- pesquisa mÃ©dica perdida
- diagnÃ³stico atrasado
- investigaÃ§Ãµes incompletas
- decisÃµes ruins

Isso Ã© exatamente o que grafos de conhecimento tentam mitigar: ligar pontos que jÃ¡ existem, mas nÃ£o estÃ£o conectados estruturalmente e semanticamente.

Um exemplo bem legal Ã© o que acontece com relatÃ³rios policiais. Na prÃ¡tica os crimes sÃ£o apenas uma sÃ©rie de pontos isolados no mapa, atÃ© que alguÃ©m estuda isso, liga esses pontos e revela um padrÃ£o de uma rede criminosa que vai desde o aliciamento de menores em comunidades carentes atÃ© os maiores empresÃ¡rios do paÃ­s e fora dele. Todos vivendo em bairros de alto padrÃ£o com uma vida luxuosa.

Veja que a falta dessas conexÃµes nÃ£o Ã© sÃ³ sobre perder ideias, pode atÃ© custar justiÃ§a. Se de fato algum homem sabeo que Ã©.

### FOUNDATION

Tudo bem atÃ© aqui? Pausa para Ã¡gua... NÃ£o?

Certo, como que se constrÃ³i essa oitava maravilha do mundo? NÃ£o gosto de ficar resumindo as coisas, mas vou trazer os famosos 3 passos, me sinto uma IA falando do tema.

- Ontologia â€” regras, classes, relaÃ§Ãµes
- ExtraÃ§Ã£o semÃ¢ntica â€” NER + Relation Extraction
- ConstruÃ§Ã£o do grafo â€” ingestÃ£o + linking + inferÃªncia

Vamos falar um pouco mais sobre a Ontologia. Ã‰ como se fosse a gramÃ¡tica deste cÃ©rebro digital. NÃ£o basta saber que existe a palavra pessoa e a palavra artigo, a ontologia Ã© que define as regras de como essas palavras se conectam. Montar uma ontologia nÃ£o Ã© apenas â€œfazer uma lista de classesâ€, Ã© um processo tÃ©cnico e metodolÃ³gico que mistura engenharia de software, filosofia, linguÃ­stica, modelagem de dados e ciÃªncia cognitiva. Vou mostrar um caso realista, incluindo tanto a parte conceitual quanto a prÃ¡tica (OWL, RDF, ferramentas, padrÃµes).

1. IdentificaÃ§Ã£o do domÃ­nio e do objetivo

Antes de criar qualquer classe, vocÃª define:

DomÃ­nio: sobre o quÃª a ontologia fala?
(ex.: futebol, crimes, biologia molecular, documentos legais)

Objetivo: para quÃª ela serÃ¡ usada?

organizar conhecimento?

alimentar um grafo de conhecimento?

permitir inferÃªncia lÃ³gica?

servir de base para NER?

Essa etapa define o escopo â€” sem isso, a ontologia vira um monstro incontrolÃ¡vel.

ðŸ§© 2. Levantamento do vocabulÃ¡rio (GlossÃ¡rio do domÃ­nio)

Aqui vocÃª coleta:

termos importantes (proteÃ­na, gene, jogador, evento...)

relaÃ§Ãµes comuns (interage_com, marca_gol, inibe, localiza...)

atributos relevantes (altura, peso, ID, tempo, data...)

sinÃ´nimos e variaÃ§Ãµes (â€œtimeâ€, â€œequipeâ€)

Fontes:

artigos cientÃ­ficos

bases de dados existentes

especialisÂ­tas do domÃ­nio

livros e reportagens

legislaÃ§Ãµes e relatÃ³rios oficiais (se for crime)

entrevistas com usuÃ¡rios

O objetivo Ã© responder:
Quais sÃ£o os elementos fundamentais desse universo?

ðŸ—‚ï¸ 3. Agrupamento em categorias (Classes)

Agora vocÃª transforma o vocabulÃ¡rio em:

classes
Ex.: Jogador, Time, Partida

subclasses
JogadorAtacante âŠ† Jogador
GeneHumano âŠ† Gene

instÃ¢ncias (opcional no comeÃ§o)
Neymar : Jogador
Palmeiras : Time

A regra tÃ©cnica:
classes representam tipos, instÃ¢ncias sÃ£o indivÃ­duos reais.

ðŸ”— 4. DefiniÃ§Ã£o das propriedades

As propriedades sÃ£o as verdadeiras joias da ontologia.

âž¤ Object Properties (ligam entidades entre si)

passaPara (Jogador â†’ Jogador)

localizadoEm (Time â†’ Cidade)

regula (Gene â†’ ProteÃ­na)

âž¤ Data Properties (ligam entidade a um literal)

temIdade : Pessoa â†’ xsd:int

temNome : Entidade â†’ xsd:string

temData : Evento â†’ xsd:date

Essas propriedades vÃ£o virar as arestas semÃ¢nticas do grafo.

ðŸ§­ 5. DefiniÃ§Ã£o de domÃ­nio, range e restriÃ§Ãµes

Agora vocÃª â€œfechaâ€ o sistema dizendo:

DomÃ­nio: quem pode usar a propriedade

Range: para onde ela pode apontar

Cardinalidade: quantos valores sÃ£o permitidos

Tipagem: obrigatoriedade de tipos

Exemplo OWL:

ObjectProperty: passaPara
    Domain: Jogador
    Range: Jogador

DataProperty: altura
    Domain: Jogador
    Range: xsd:float


Isso permite ao motor inferir erros e novos fatos.

ðŸ§® 6. Modelagem lÃ³gica (restriÃ§Ãµes OWL)

Aqui entra a parte formal da ontologia.

VocÃª cria axiomas:

âœ” Classes disjuntas
DisjointClasses: Atacante, Goleiro, Zagueiro

âœ” RestriÃ§Ãµes existenciais (algum)

â€œTodo jogador joga em pelo menos um timeâ€

Jogador SubClassOf jogaEm some Time

âœ” RestriÃ§Ãµes universais (somente)

â€œTodo gol Ã© marcado apenas por jogadoresâ€

Gol SubClassOf marcadoPor only Jogador

âœ” Regras lÃ³gicas

â€œSe algo Ã© um gene e regula outra coisa, entÃ£o Ã© um reguladorâ€
(com reasoner automÃ¡tico)

ðŸ§ª 7. Testes com um reasoner semÃ¢ntico (HermiT, Pellet, FaCT++)

O reasoner verifica:

inconsistÃªncias (â€œAtacante Ã© jogador, mas vocÃª disse que Jogador Ã© disjunto de Atacanteâ€)

inferÃªncias novas (â€œse X Ã© Partida e tem Data, entÃ£o Ã© um Eventoâ€)

redundÃ¢ncias

erros de cardinalidade

Isso garante que a ontologia Ã© sÃ³lida matematicamente.

ðŸ“¦ 8. ImplementaÃ§Ã£o em OWL / RDF

A ontologia agora Ã© codificada em formatos padrÃµes:

OWL (Web Ontology Language â€” o mais usado)

RDF(S) â€” mais simples

SHACL â€” para validaÃ§Ã£o de grafos

A ferramenta mais comum Ã©:

âž¤ ProtÃ©gÃ©

Um editor visual (gratuito) usado no mundo inteiro.

VocÃª usa ProtÃ©gÃ© para:

criar classes

definir restriÃ§Ãµes

rodar reasoners

exportar para OWL

visualizar o grafo

ðŸ§± 9. PopulaÃ§Ã£o do grafo (instÃ¢ncias reais)

Com a ontologia pronta, vocÃª comeÃ§a a adicionar:

pessoas reais

genes reais

jogadores reais

eventos reais

crimes reais

Isso pode ser:

manual (demorado)

automÃ¡tico (com NER + Entity Linking + Relation Extraction)

Essa etapa gera milhÃµes (ou bilhÃµes) de triplas.

ðŸ”— 10. IntegraÃ§Ã£o com sistemas que vÃ£o usar o grafo

A ontologia agora serve de base para:

mecanismos de NER semÃ¢ntico (baseados em classes)

motores de recomendaÃ§Ã£o

sistemas jurÃ­dicos

descoberta de medicamentos

grafos de compliance

sistemas de busca inteligente

---

Ã‰ preciso criar o que os engenheiros e arquitetos chamariam de planta baixa, um projeto, que os mais prÃ³ximos chamam de ontologia, no fundo Ã© o livro de regras que diz o que Ã© importante e o que estamos procurando.

Depois o computador analisa os textos e extrai os fatos importantes e por fim vem a mÃ¡gica. (NÃ£o tem mÃ¡gica infelizmente...) No final ele constrÃ³i a rede conectando os pontos para gerar o conhecimento

Exemplo: Uma pessoa pode ser autora de um artigo

Ã‰ essa estrutura que transforma uma lista de informaÃ§Ãµes soltas em uma rede de conhecimento que faz sentido.

Certo, mas como esse ecossistema, se podemos chamar assim, encontras os dados para preencher essa estrutura. Ai vamos comeÃ§ar a ser mais tÃ©cnicos, nesse ponto entra um processo chamado "Reconhecimento de entidades nomeadas (NER)"

Uma forma de simplificaÃ§Ã£o para o entendimento disso, Ã© como se fosse um marcador de texto super inteligente. O modelo lÃª o documento e vai destacando o que Ã© uma pessoa, o que Ã© uma organizaÃ§Ã£o, o que Ã© um termo tÃ©cnico e atÃ© o que Ã© uma apresentaÃ§Ã£o ruim. Ã‰ assim que a matÃ©ria-prima do conhecimento Ã© recolhida do texto bruto. E olhem sÃ³ para este exemplo que mostra isto na perfeiÃ§Ã£o. Ã‰ um antes e um depois. Ã€ esquerda temos um trecho normal de um artigo da NASA e Ã  direita o mesmo texto, mas depois de passar pelo processo de NER. Vejam como o sistema identificou sozinho que Ryan McGranhan Ã© uma pessoa e que NASA e CFAH sÃ£o organizaÃ§Ãµes. Ã‰ aqui que a mÃ¡quina comeÃ§a a enxergar o significado por trÃ¡s das palavras.

Uma forma mais tÃ©cnica: NER Ã© uma das primeiras etapas na construÃ§Ã£o de um grafo de conhecimento. Ele identifica â€œcoisasâ€ no texto, pessoas, locais, organizaÃ§Ãµes, conceitos etc para que depois possamos ligÃ¡-las em forma de grafo.

Deixa eu dividir em passos para facilitar

1. Entrada: texto nÃ£o estruturado

Exemplos: â€œO Marcello vai pontuar o JoÃ£o e o Breno com A na matÃ©ria no final do semestre.â€

O primeiro passo Ã© transformar esse texto em entidades e relaÃ§Ãµes.

2. NER â€” Reconhecimento de Entidades Nomeadas

O NER identifica e classifica entidades no texto. Os modelos comuns: spaCy, BERT, RoBERTa, Flair, GPT, Stanza. SÃ£o prÃ©-treinados para isso. O NER rotula trechos com categorias como:

PERSON
ORG
LOCATION
DATE
PRODUCT

Marcello, JoÃ£o, Breno â†’ PERSON
final do semestre â†’ DATE

3. NormalizaÃ§Ã£o / DesambiguaÃ§Ã£o (Entity Linking)

NER sÃ³ detecta o nome â€” mas nÃ£o sabe qual Apple, nem qual Alan Turing em um banco de dados maior.

Entity Linking conecta cada entidade ao seu ID global:

Alan Turing â†’ wikidata:Q7259

Apple â†’ wikidata:Q312

1940 â†’ wikidata:Q1994

Isso evita duplicaÃ§Ã£o e permite unificar dados.

4. ExtraÃ§Ã£o de relaÃ§Ãµes (Relation Extraction)

Depois que temos entidades, o sistema determina como elas se conectam.

TÃ©cnicas:

Regras linguÃ­sticas (sujeitoâ€“verboâ€“objeto)

DependÃªncia sintÃ¡tica

Modelos supervisionados (BERT para RE)

Modelos grandes (LLMs) para extraÃ§Ã£o supervisionada ou zero-shot

Exemplo:
Texto:

"Turing trabalhou na Apple."

RelaÃ§Ã£o extraÃ­da:

(Alan Turing) â€” trabalhou em â†’ (Apple)

5. ConstruÃ§Ã£o do grafo

Cada entidade vira um nÃ³
Cada relaÃ§Ã£o vira uma aresta
Cada tipo de entidade vira um rÃ³tulo

Exemplo de grafo:
Alan Turing --trabalhou em--> Apple
Alan Turing --atividade em--> 1940

RepresentaÃ§Ãµes comuns:

RDF / OWL (Web SemÃ¢ntica)

Property Graph (Neo4j)

GraphML / NetworkX

6. Enriquecimento

O grafo pode ser expandido com:

informaÃ§Ãµes adicionais da web

bases estruturadas (DBpedia, Wikidata)

outros documentos processados por NER

7. Armazenamento e consulta

Com o grafo montado, vocÃª pode consultar com:

SPARQL (RDF)

Cypher (Neo4j)

Gremlin

Exemplo em Cypher:

MATCH (p:Person)-[:TRABALHOU_EM]->(o:Organization)
RETURN p, o;

Mas quÃ£o bom Ã© o sistema a fazer isto?. Bem, estes nÃºmeros de um caso de estudo real da NASA dÃ£o-nos uma ideia muito clara. A **precisÃ£o [Ã© de] 100%**. Isto Ã© incrÃ­vel. Significa que tudo o que ele identifica, identifica corretamente. SÃ³ que o **recall Ã© de 66,6%**. O que Ã© que isto quer dizer?. Que ele ainda deixa escapar mais ou menos 1/3 dos peixes que estÃ£o no lago. Ou seja, ele Ã© super preciso no que apanha, mas ainda precisa de aprender a apanhar tudo o que existe.

Tudo bem, a teoria Ã© interessante, mas e na prÃ¡tica? Porque ter todo esse trabalho?
Nada como exemplos concretos do mundo real. Olhem este caso. 

Em Modena, na ItÃ¡lia, a polÃ­cia lÃ¡ usa esta tecnologia para ligar os pontos nos relatÃ³rios de crimes. Pensem bem, um roubo aqui, um carro suspeito, avistado ali. Sozinhos sÃ£o sÃ³ ruÃ­do, informaÃ§Ã£o solta. Mas o **grafo de conhecimento consegue ligar esses pontos**, seja por um local, um horÃ¡rio ou uma descriÃ§Ã£o em comum. E de repente ele revela padrÃµes que um analista humano talvez nunca conseguisse ver. Ele transforma dados aleatÃ³rios numa ferramenta poderosa de prevenÃ§Ã£o.

E na educaÃ§Ã£o, o potencial Ã© de revolucionar a forma como se aprende. Imaginem um sistema que entende que a competÃªncia em Ã¡lgebra linear estÃ¡ muito ligada a *machine learning*. Se um aluno vai bem na primeira, o sistema pode, de forma proativa, sugerir a segunda. Isto cria um **caminho de aprendizagem totalmente personalizado** que se adapta aos pontos fortes de cada um. Em vez daquele *curriculum* de tamanho Ãºnico que conhecemos.

Agora, um exemplo que Ã© literalmente uma **questÃ£o de vida ou morte**. No sul da NigÃ©ria, um sistema usa um grafo de conhecimento para traduzir alertas de emergÃªncia para lÃ­nguas locais que muitas vezes os tradutores automÃ¡ticos normais nÃ£o cobrem. Isto simplesmente **quebra barreiras linguÃ­sticas em situaÃ§Ãµes crÃ­ticas**, garantindo que informaÃ§Ãµes vitais cheguem a quem precisa na hora certa.

Pois Ã©, todos estes exemplos apontam para uma direÃ§Ã£o muito clara. NÃ£o estamos a falar de uma melhoria pequena, incremental. Estamos a falar de uma **mudanÃ§a fundamental na maneira como interagimos com a informaÃ§Ã£o**. EntÃ£o, para resumir a ideia central, os grafos de conhecimento **tornam o inacessÃ­vel acessÃ­vel**. Eles permitem-nos encontrar aquela **agulha no palheiro de dados**, seja a conectar pesquisas cientÃ­ficas, a ajudar a combater o crime ou, como vimos, atÃ© salvar vidas. NÃ³s deixamos de apenas procurar informaÃ§Ã£o para passar a **dialogar com ela, a fazer-lhe perguntas de verdade**. E tudo isto leva-nos a uma reflexÃ£o final. NÃ³s estamos a construir mÃ¡quinas que nÃ£o sÃ³ processam palavras, elas estÃ£o a comeÃ§ar a **entender o mundo de ideias por trÃ¡s delas**. E Ã  medida que esta tecnologia se torna cada vez mais poderosa, a pergunta mais importante talvez nÃ£o seja o que Ã© que ela pode fazer, mas sim que perguntas Ã© que nÃ³s vamos escolher fazer-lhe primeiro? Fica a reflexÃ£o.


### Resultado

Depois de montar um grafo de conhecimento, vocÃª pode usÃ¡-lo em Machine Learning de vÃ¡rias maneiras. Existem trÃªs formas principais:

# 1. Usar o grafo como entrada para modelos (via embeddings)

Modelos de ML nÃ£o trabalham diretamente com grafos â†’ eles trabalham com vetores. Por isso, o passo mais comum Ã© transformar o grafo em embeddings.

### Como gerar embeddings de grafo

Use algoritmos de aprendizado de representaÃ§Ã£o:

### ClÃ¡ssicos

- Node2Vec
- DeepWalk
- GraphSAGE

### Via GNNs (Graph Neural Networks)

- GCN (Graph Convolutional Network)
- GAT (Graph Attention Network)
- GraphSAGE (versÃ£o neural)

Esses mÃ©todos geram vetores como:

$\mathbf{h}_v \in \mathbb{R}^d$

para cada nÃ³ (v).

Depois disso vocÃª pode usar esses vetores em:

* ClassificaÃ§Ã£o
* RegressÃ£o
* Clustering
* Sistemas de recomendaÃ§Ã£o
* DetecÃ§Ã£o de anomalias
* PrediÃ§Ã£o de links

---

# âœ… 2. Usar o grafo como parte de um modelo de RaciocÃ­nio

Aqui a lÃ³gica ou estrutura do grafo Ã© usada para ajudar o modelo, por exemplo:

* Inferir novos fatos (link prediction)
* Propagar informaÃ§Ã£o entre entidades conectadas
* Raciocinar sobre relaÃ§Ãµes (ex: â€œX Ã© pai de Y, entÃ£o ...â€)

Exemplos de uso:

* Sistemas de recomendaÃ§Ã£o que usam grafos usuÃ¡rioâ€“item.
* NER + Knowledge Graph para desambiguar entidades.
* Chatbots + grafos para grounding.

---

# âœ… **3. Misturar grafo + dados nÃ£o estruturados**

Essa Ã© a abordagem usada por modelos modernos multimodais.

Exemplos:

* **GNN + CNN** â†’ visÃ£o + grafo
* **Transformers + KG embeddings** â†’ LLMs + grafo
* **KG + dados tabulares** â†’ melhorar modelos tabulares

---

# ðŸ“Œ Exemplos prÃ¡ticos de uso

## **ðŸŸ¦ (A) ClassificaÃ§Ã£o de nÃ³s**

VocÃª tem um grafo e quer prever o tipo de uma entidade.

**Entrada:** grafo
**SaÃ­da:** classe de cada nÃ³

Usa GNN:

[
\mathbf{h}_v^{(k+1)} = \text{AGG}({\mathbf{h}_u^{(k)} : u \in \mathcal{N}(v)})
]

Distribui informaÃ§Ã£o entre vizinhos.

---

## **ðŸŸ© (B) PrediÃ§Ã£o de links**

Prever se duas entidades tÃªm uma relaÃ§Ã£o.

[
p(u \sim v) = \sigma(\mathbf{h}_u^\top \mathbf{h}_v)
]

Usado em:

* RecomendaÃ§Ã£o (â€œusuÃ¡rio X possivelmente gosta do item Y?â€)
* Descoberta de conhecimento
* Biologia (interaÃ§Ãµes proteÃ­na-proteÃ­na)

---

## **ðŸŸ§ (C) ClassificaÃ§Ã£o de grafo inteiro**

Se cada grafo Ã© um item (ex: molÃ©cula):

[
\hat{y} = f(\text{READOUT}({\mathbf{h}_v}))
]

---

# Resumo simples

> Depois de montar um grafo, vocÃª o transforma em **embeddings** usando mÃ©todos de grafos (Node2Vec, GNNs).
> Esses embeddings viram entrada para modelos de Machine Learning para tarefas de classificaÃ§Ã£o, regressÃ£o, recomendaÃ§Ã£o, raciocÃ­nio ou previsÃ£o de relaÃ§Ãµes.

---

Se quiser, posso te mostrar **um pipeline completo**, um **exemplo em Python (PyTorch Geometric / DGL)**, ou **qual mÃ©todo usar para o seu caso especÃ­fico**.


Aqui vai **um exemplo simples e didÃ¡tico** de como usar um grafo de conhecimento em Machine Learning.
Vou fazer assim:

1. **Criar um pequeno grafo**
2. **Gerar embeddings (Node2Vec)**
3. **Usar esses embeddings em um modelo de classificaÃ§Ã£o (Logistic Regression)**

Tudo bem simples e fÃ¡cil de entender.

---

# Construindo um grafo

Suponha este grafo de conhecimento:

* Pessoa A gosta de Filme X
* Pessoa B gosta de Filme Y
* Pessoa C gosta de Filme X
* A Ã© amigo de B
* B Ã© amigo de C

Representamos como nÃ³s + arestas:

```
A --- gosta ---> X
B --- gosta ---> Y
C --- gosta ---> X

A --- amigo --- B --- amigo --- C
```

NÃ³s:

* A, B, C (pessoas)
* X, Y (filmes)

---

# âœ… **2. Gerando embeddings com Node2Vec**

Node2Vec aprende vetores que representam os nÃ³s do grafo.

Aqui vai um exemplo em Python usando **NetworkX + Node2Vec**:

```python
from node2vec import Node2Vec
import networkx as nx
from sklearn.linear_model import LogisticRegression
import numpy as np

# criar grafo
G = nx.Graph()
G.add_edges_from([
    ("A", "X"),
    ("B", "Y"),
    ("C", "X"),
    ("A", "B"),
    ("B", "C")
])

# gerar embeddings com Node2Vec
node2vec = Node2Vec(G, dimensions=8, walk_length=10, num_walks=50)
model = node2vec.fit(window=5, min_count=1)

# pegar vetor de cada nÃ³
A_vec = model.wv["A"]
B_vec = model.wv["B"]
C_vec = model.wv["C"]
X_vec = model.wv["X"]
Y_vec = model.wv["Y"]
```

Agora cada nÃ³ Ã© um vetor, por exemplo:

```
A â†’ [0.21, -0.44, 1.02, ...]
B â†’ [...]
X â†’ [...]
```

---

# âœ… **3. Usando embeddings em ML**

Imagine que queremos **classificar pessoas como "parecidas com A" ou nÃ£o**.

RÃ³tulos para exemplo:

```
A â†’ 1
B â†’ 1
C â†’ 0
```

Treinando:

```python
X_train = np.array([
    A_vec,
    B_vec,
    C_vec
])

y_train = np.array([1, 1, 0])

clf = LogisticRegression()
clf.fit(X_train, y_train)
```

Agora podemos classificar qualquer nÃ³ baseado em **sua posiÃ§Ã£o no grafo**.

---

# ðŸ“Œ **O que aconteceu aqui?**

* O grafo foi convertido em embeddings com Node2Vec.
* Os embeddings foram usados como features em um modelo de ML tradicional.

Ou seja:

> **Grafo â†’ Vetores â†’ Aprendizado de MÃ¡quina**

---

# ðŸ”¥ Se quiser, posso:

âœ” montar um exemplo com **GNN (GCN ou GraphSAGE)**
âœ” usar **PyTorch Geometric (PyG)**
âœ” mostrar visualizaÃ§Ã£o do grafo
âœ” mostrar como usar esse pipeline para *recomendaÃ§Ã£o* (usuÃ¡rio â†’ item)